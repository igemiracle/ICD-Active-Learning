{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b031da0f-c98d-482b-a203-9b845c31a16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "04d47dc3-b5e8-4581-ad24-12296800b57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TFIDF_LR_Classifier:\n",
    "    def __init__(self, max_features=10000, ngram_range=(1, 2), C=1.0, n_jobs=-1):\n",
    "        self.vectorizer = TfidfVectorizer(max_features=max_features, ngram_range=ngram_range)\n",
    "        self.C = C\n",
    "        self.n_jobs = n_jobs\n",
    "        self.mlb = MultiLabelBinarizer()\n",
    "        self.models = []  # List of trained classifiers\n",
    "\n",
    "    def _train_one(self, X, y_col):\n",
    "        if np.sum(y_col == 0) > 0 and np.sum(y_col == 1) > 0:\n",
    "            model = LogisticRegression(\n",
    "                C=self.C,\n",
    "                solver='saga',\n",
    "                penalty='l2',\n",
    "                max_iter=1000,\n",
    "                n_jobs=1,\n",
    "                random_state=42\n",
    "            )\n",
    "            model.fit(X, y_col)\n",
    "            return model\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def fit(self, texts, labels):\n",
    "        print(\"Fitting TF-IDF vectorizer...\")\n",
    "        X = self.vectorizer.fit_transform(texts)\n",
    "        Y = self.mlb.fit_transform(labels)\n",
    "        print(\"Training Logistic Regression classifiers (parallelized)...\")\n",
    "\n",
    "        results = Parallel(n_jobs=self.n_jobs)(\n",
    "            delayed(self._train_one)(X, Y[:, i]) for i in tqdm(range(Y.shape[1]), desc=\"Training per-label models\")\n",
    "        )\n",
    "\n",
    "        self.models = results\n",
    "\n",
    "    def predict(self, texts):\n",
    "        X = self.vectorizer.transform(texts)\n",
    "        predictions = []\n",
    "        for model in self.models:\n",
    "            if model is not None:\n",
    "                pred = model.predict(X)\n",
    "            else:\n",
    "                pred = np.zeros(X.shape[0], dtype=int)\n",
    "            predictions.append(pred)\n",
    "        Y_pred = np.stack(predictions, axis=1)\n",
    "        return self.mlb.inverse_transform(Y_pred)\n",
    "\n",
    "    def predict_proba(self, texts):\n",
    "        X = self.vectorizer.transform(texts)\n",
    "        probabilities = []\n",
    "        for model in self.models:\n",
    "            if model is not None:\n",
    "                prob = model.predict_proba(X)[:, 1]\n",
    "            else:\n",
    "                prob = np.zeros(X.shape[0])\n",
    "            probabilities.append(prob)\n",
    "        return np.stack(probabilities, axis=1)\n",
    "\n",
    "    def evaluate(self, texts, labels):\n",
    "        X = self.vectorizer.transform(texts)\n",
    "        Y_true = self.mlb.transform(labels)\n",
    "        predictions = []\n",
    "        for model in self.models:\n",
    "            if model is not None:\n",
    "                pred = model.predict(X)\n",
    "            else:\n",
    "                pred = np.zeros(X.shape[0], dtype=int)\n",
    "            predictions.append(pred)\n",
    "        Y_pred = np.stack(predictions, axis=1)\n",
    "        micro = f1_score(Y_true, Y_pred, average='micro')\n",
    "        macro = f1_score(Y_true, Y_pred, average='macro')\n",
    "        return {'micro_f1': micro, 'macro_f1': macro}\n",
    "\n",
    "    def save(self, path_prefix):\n",
    "        with open(path_prefix + '_vectorizer.pkl', 'wb') as f:\n",
    "            pickle.dump(self.vectorizer, f)\n",
    "        with open(path_prefix + '_models.pkl', 'wb') as f:\n",
    "            pickle.dump(self.models, f)\n",
    "        with open(path_prefix + '_mlb.pkl', 'wb') as f:\n",
    "            pickle.dump(self.mlb, f)\n",
    "\n",
    "    def load(self, path_prefix):\n",
    "        with open(path_prefix + '_vectorizer.pkl', 'rb') as f:\n",
    "            self.vectorizer = pickle.load(f)\n",
    "        with open(path_prefix + '_models.pkl', 'rb') as f:\n",
    "            self.models = pickle.load(f)\n",
    "        with open(path_prefix + '_mlb.pkl', 'rb') as f:\n",
    "            self.mlb = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b6eb99da-fcbd-418f-95dc-f81a99953c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载数据\n",
    "df = pd.read_pickle('../data/mimic3_data_test.pkl')\n",
    "texts = df['TEXT'].tolist()\n",
    "labels = df['ICD9_CODE'].tolist()\n",
    "\n",
    "# 划分训练/验证集\n",
    "X_train, X_val, y_train, y_val = train_test_split(texts, labels, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b28a26-f3d1-4e37-b367-7cd1e70cd730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting TF-IDF vectorizer...\n",
      "Working on model 7\n",
      "Working on model 8\n",
      "Working on model 6\n",
      "Working on model 9\n",
      "Working on model 3\n",
      "Working on model 10\n",
      "Working on model 0\n",
      "Working on model 12\n",
      "Working on model 1\n",
      "Working on model 13\n",
      "Working on model 2\n",
      "Working on model 11\n",
      "Working on model 4\n",
      "Working on model 14\n",
      "Working on model 5\n",
      "Working on model 15\n",
      "Training Logistic Regression classifiers (parallelized)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training per-label models:   1%|▏                       | 64/6599 [00:31<1:02:35,  1.74it/s]/ocean/projects/bio200049p/yzheng9/conda_envs/llm/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/ocean/projects/bio200049p/yzheng9/conda_envs/llm/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/ocean/projects/bio200049p/yzheng9/conda_envs/llm/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/ocean/projects/bio200049p/yzheng9/conda_envs/llm/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/ocean/projects/bio200049p/yzheng9/conda_envs/llm/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/ocean/projects/bio200049p/yzheng9/conda_envs/llm/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/ocean/projects/bio200049p/yzheng9/conda_envs/llm/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/ocean/projects/bio200049p/yzheng9/conda_envs/llm/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/ocean/projects/bio200049p/yzheng9/conda_envs/llm/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/ocean/projects/bio200049p/yzheng9/conda_envs/llm/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/ocean/projects/bio200049p/yzheng9/conda_envs/llm/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/ocean/projects/bio200049p/yzheng9/conda_envs/llm/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "Training per-label models:   1%|▎                      | 96/6599 [20:07<30:51:57, 17.09s/it]/ocean/projects/bio200049p/yzheng9/conda_envs/llm/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/ocean/projects/bio200049p/yzheng9/conda_envs/llm/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/ocean/projects/bio200049p/yzheng9/conda_envs/llm/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/ocean/projects/bio200049p/yzheng9/conda_envs/llm/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/ocean/projects/bio200049p/yzheng9/conda_envs/llm/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/ocean/projects/bio200049p/yzheng9/conda_envs/llm/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/ocean/projects/bio200049p/yzheng9/conda_envs/llm/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 初始化与训练模型\n",
    "clf = TFIDF_LR_Classifier(max_features=10000, ngram_range=(1,2), C=1.0)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# 评估\n",
    "results = clf.evaluate(X_val, y_val)\n",
    "print(\"Validation Micro-F1:\", results['micro_f1'])\n",
    "print(\"Validation Macro-F1:\", results['macro_f1'])\n",
    "\n",
    "\n",
    "# 可选：保存模型\n",
    "clf.save('../models/tfidf_lr_baseline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eb606ab5-50ce-41bb-9b57-248738995f57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on model 4\n",
      "Working on model 5\n",
      "Working on model 6\n",
      "Working on model 8\n",
      "Working on model 1\n",
      "Working on model 3\n",
      "Working on model 2\n",
      "Working on model 9\n",
      "Working on model 10\n",
      "Working on model 0\n",
      "Working on model 7\n",
      "Working on model 11\n",
      "Working on model 15\n",
      "Working on model 12\n",
      "Working on model 13\n",
      "Working on model 14\n",
      "Working on model 10\n",
      "Working on model 0\n",
      "Working on model 2\n",
      "Working on model 1\n",
      "Working on model 3\n",
      "Working on model 2\n",
      "Working on model 0\n",
      "Working on model 5\n",
      "Working on model 8\n",
      "Working on model 3\n",
      "Working on model 6\n",
      "Working on model 4\n",
      "Working on model 4\n",
      "Working on model 6\n",
      "Working on model 11\n",
      "Working on model 7\n",
      "Working on model 9\n",
      "Working on model 8\n",
      "Working on model 12\n",
      "Working on model 9\n",
      "Working on model 1\n",
      "Working on model 10\n",
      "Working on model 14\n",
      "Working on model 11\n",
      "Working on model 15\n",
      "Working on model 12\n",
      "Working on model 7\n",
      "Working on model 13\n",
      "Working on model 13\n",
      "Working on model 14\n",
      "Working on model 5\n",
      "Working on model 15\n",
      "Time used: 2.5765438079833984\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "def work(i):\n",
    "    print(f\"Working on model {i}\")\n",
    "    time.sleep(1)  # 模拟训练耗时\n",
    "    return i\n",
    "\n",
    "start = time.time()\n",
    "results = Parallel(n_jobs=10)(delayed(work)(i) for i in range(16))\n",
    "end = time.time()\n",
    "print(\"Time used:\", end - start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778be71f-0cf7-47c4-aad7-781758db17b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
